{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1520d4f8",
   "metadata": {},
   "source": [
    "üìù Notebook Scraping Data Sekolah\n",
    "\n",
    "Notebook ini digunakan untuk **scraping data sekolah di Indonesia** dari website [SekolahKita](https://sekolah.data.kemendikdasmen.go.id/).  \n",
    "\n",
    "Tujuan dari notebook ini:  \n",
    "- Mengumpulkan data sekolah per jenjang (SMA, SMK, MA, dll). Pada kasus ini berfokus pada data SMA.\n",
    "- Menyimpan hasil scraping per batch untuk menghindari timeout atau error  \n",
    "- Menggabungkan semua batch menjadi satu file CSV utama  \n",
    "- Menyediakan data yang siap digunakan untuk **analisis, visualisasi, atau scraping profil sekolah lebih detail** di notebook lanjutan `2_scraping_profil`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a65f7",
   "metadata": {},
   "source": [
    "# **LIBRARY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394720d",
   "metadata": {},
   "source": [
    "Proyek ini menggunakan beberapa library dari **Python Standard Library**, **Third-party**, dan tools untuk menjalankan proses **paralel** agar scraping lebih efisien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd7e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# Standard Library\n",
    "# ============================\n",
    "import os               # Operasi sistem (buat folder, path, dll)\n",
    "import math             # Fungsi matematika (ceil, floor, dll)\n",
    "import glob             # Operasi file dengan pola tertentu\n",
    "import pandas as pd     # Manipulasi data tabel (DataFrame)\n",
    "import re\n",
    "\n",
    "# ============================\n",
    "# Third-party Libraries\n",
    "# ============================\n",
    "import requests                # HTTP request (scraping data dari web)\n",
    "from bs4 import BeautifulSoup  # Parsing HTML\n",
    "from tqdm import tqdm          # Progress bar interaktif\n",
    "\n",
    "# ============================\n",
    "# Concurrency Utilities\n",
    "# ============================\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # Multi-worker/concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd2f08",
   "metadata": {},
   "source": [
    "# **FUNGSI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb5024",
   "metadata": {},
   "source": [
    "Di bagian ini, dibuat dua fungsi utama untuk scraping data sekolah:  \n",
    "\n",
    "1. `extract_data(soup)` ‚Üí mengekstrak informasi dari HTML, dipakai di dalam fungsi `scrape_pages()`.  \n",
    "2. `scrape_pages(page_mulai, page_selesai, jenjang, nama_file)` ‚Üí melakukan scraping per halaman dan menyimpan hasil ke CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Fungsi Extract Data\n",
    "# ============================\n",
    "def extract_data(soup):\n",
    "    \"\"\"\n",
    "    Ekstrak data sekolah dari halaman HTML.\n",
    "    Mengambil: nama, link profil, alamat, kabupaten, kota, provinsi.\n",
    "    \"\"\"\n",
    "    semua_data = []\n",
    "    blocks = soup.find_all(\"div\", class_=\"box box-default\")  # setiap sekolah ditampilkan dalam blok HTML\n",
    "\n",
    "    for block in blocks:\n",
    "        # Ambil nama sekolah dan link profil\n",
    "        nama_tag = block.find(\"a\", class_=\"text-info\")\n",
    "        if not nama_tag:\n",
    "            continue\n",
    "\n",
    "        kode_nama = nama_tag.get_text(strip=True)\n",
    "        kode = re.search(r'\\((\\d+)\\)', kode_nama).group(1)\n",
    "        nama = re.sub(r'\\(\\d+\\)\\s*', '', kode_nama)\n",
    "        link = nama_tag.get(\"href\", \"\")\n",
    "\n",
    "        # Ambil alamat (bisa terdiri dari beberapa elemen <li>)\n",
    "        alamat_tags = block.find_all(\"li\", class_=\"list-group-item text-muted\")\n",
    "        alamat_list = [tag.get_text(strip=True) for tag in alamat_tags]\n",
    "        alamat = \" \".join(alamat_list)\n",
    "\n",
    "        # Inisialisasi wilayah\n",
    "        kabupaten, kota, provinsi = \"\", \"\", \"\"\n",
    "        for tag in alamat_list:\n",
    "            if \"Prov.\" in tag:  # format biasanya \"Kab./Kota X Prov. Y\"\n",
    "                bagian = tag.split(\"Prov.\")\n",
    "                wilayah = bagian[0].strip()\n",
    "                provinsi = bagian[1].strip()\n",
    "\n",
    "                if wilayah.startswith(\"Kab.\"):\n",
    "                    kabupaten = wilayah\n",
    "                elif wilayah.startswith(\"Kota\"):\n",
    "                    kota = wilayah\n",
    "                break\n",
    "\n",
    "        # Simpan hasil\n",
    "        semua_data.append({\n",
    "            \"kode\":kode,\n",
    "            \"nama\": nama,\n",
    "            \"link_profil\": link,\n",
    "            \"alamat\": alamat,\n",
    "            \"kabupaten\": kabupaten,\n",
    "            \"kota\": kota,\n",
    "            \"provinsi\": provinsi\n",
    "        })\n",
    "\n",
    "    return semua_data\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Fungsi Scrape Pages\n",
    "# ============================\n",
    "def scrape_pages(page_mulai, page_selesai, jenjang, nama_file):\n",
    "    \"\"\"\n",
    "    Scrape data sekolah berdasarkan halaman dan jenjang.\n",
    "    Menyimpan hasil ke CSV.\n",
    "    \"\"\"\n",
    "    url = \"https://sekolah.data.kemendikdasmen.go.id/index.php/Chome/pencarian/\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    semua_data = []\n",
    "\n",
    "    # Loop tiap halaman\n",
    "    for page in range(page_mulai, page_selesai + 1):\n",
    "        payload = {\n",
    "            \"page\": page,\n",
    "            \"kode_kabupaten\": \"\",\n",
    "            \"kode_kecamatan\": \"\",\n",
    "            \"bentuk_pendidikan\": jenjang,\n",
    "            \"status_sekolah\": \"semua\",\n",
    "            \"nama\": \"\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Request POST\n",
    "            response = requests.post(url, data=payload, headers=headers, timeout=15)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö† Halaman {page} tidak berhasil diakses (status {response.status_code})\")\n",
    "                continue\n",
    "\n",
    "            # Parsing HTML hasil response\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            semua_data.extend(extract_data(soup))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{nama_file}] ‚ùå Error di halaman {page}: {e}\")\n",
    "\n",
    "    # Simpan ke CSV dengan pandas\n",
    "    if semua_data:\n",
    "        df = pd.DataFrame(semua_data)\n",
    "        df.to_csv(nama_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"[{nama_file}] ‚úÖ Disimpan {len(df)} baris\")\n",
    "    else:\n",
    "        print(f\"[{nama_file}] ‚ö† Tidak ada data disimpan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebd7b9",
   "metadata": {},
   "source": [
    "# **KONFIGURASI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9e7f3",
   "metadata": {},
   "source": [
    "Di bagian ini, kita menyiapkan parameter untuk proses scraping.\n",
    "\n",
    "> Tabel berikut menjelaskan parameter yang digunakan beserta fungsinya:\n",
    "\n",
    "| Parameter       | Keterangan                                                   | Fungsi                                                                 |\n",
    "|-----------------|-------------------------------------------------------------|------------------------------------------------------------------------|\n",
    "| `jenjang`       | Jenjang sekolah (SMA, SMK, MA, dll). Pada kasus ini SMA      | Digunakan sebagai payload request dan nama folder output               |\n",
    "| `folder`        | Folder output untuk menyimpan CSV                            | Menyimpan hasil scraping agar terorganisir per jenjang                 |\n",
    "| `page_mulai`    | Halaman awal scraping                                        | Menentukan halaman pertama yang akan di-scrape                          |\n",
    "| `page_selesai`  | Halaman akhir scraping                                       | Menentukan halaman terakhir yang akan di-scrape                         |\n",
    "| `batch_size`    | Ukuran batch untuk scraping                                   | Membagi total halaman menjadi batch agar lebih mudah dikelola          |\n",
    "| `MAX_WORKER`    | Jumlah worker paralel                                        | Menentukan jumlah thread yang dijalankan secara bersamaan untuk efisiensi |\n",
    "\n",
    "---\n",
    "\n",
    "> üìå Catatan `batch_size` dan `MAX_WORKER`\n",
    "\n",
    "- Misalkan `page_mulai = 1`, `page_selesai = 3745`, dan `batch_size = 100`, maka hasil scraping akan dibagi menjadi **38 file CSV**, masing-masing bernama:  \n",
    "  - batch_1-100.csv\n",
    "  - batch_101-200.csv\n",
    "  - batch_201-300.csv\n",
    "  - ‚Ä¶ \n",
    "  - batch_3701-380.csv\n",
    "  \n",
    "  Informasi jumlah halaman dapat dilihat pada website: [SekolahKita](https://sekolah.data.kemendikdasmen.go.id/)\n",
    "\n",
    "\n",
    "- **Jumlah worker (`MAX_WORKER`)**:  \n",
    "  Makin banyak worker ‚Üí makin banyak request yang dikirim secara bersamaan ‚Üí lebih cepat, tapi **rawan error** akibat koneksi internet atau limit server.\n",
    "\n",
    "- **Batch size (`batch_size`)**:  \n",
    "  - Makin besar batch ‚Üí tiap file CSV berisi lebih banyak halaman ‚Üí efisien dalam penyimpanan.  \n",
    "  - Tapi batch besar juga ‚Üí proses tiap batch lebih lama dan jika terjadi error, harus ulang batch besar tersebut.  \n",
    "  - Makin kecil batch ‚Üí lebih sering menulis file CSV ‚Üí lebih aman jika ada error, tapi lebih banyak file CSV yang dihasilkan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63097a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scraping: 100 halaman (2 batch, batch size 50)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Parameter Scraping\n",
    "# ----------------------------\n",
    "jenjang = \"SMA\"\n",
    "folder = f\"../hasil/data_halaman/{jenjang.lower()}\"\n",
    "os.makedirs(folder, exist_ok=True)  # buat folder jika belum ada\n",
    "\n",
    "page_mulai = 1\n",
    "page_selesai = 100\n",
    "batch_size = 50\n",
    "MAX_WORKER = 2\n",
    "\n",
    "# Hitung total halaman & batch\n",
    "total_halaman = page_selesai - page_mulai + 1\n",
    "total_batch = math.ceil(total_halaman / batch_size)\n",
    "\n",
    "print(f\"Total scraping: {total_halaman} halaman ({total_batch} batch, batch size {batch_size})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fdd7f",
   "metadata": {},
   "source": [
    "# **SCRAPPING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fcc11",
   "metadata": {},
   "source": [
    "Di bagian ini, kita melakukan scraping data menggunakan fungsi `scrape_pages()` yang sudah dibuat.  \n",
    "Terdapat dua versi:\n",
    "1. Tanpa multi-worker ‚Üí berjalan secara berurutan.\n",
    "2. Dengan multi-worker ‚Üí proses paralel lebih cepat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fe670",
   "metadata": {},
   "source": [
    "## **Tanpa Multi-Worker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94e864a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Mulai scraping 10 halaman (1 batch, batch size 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping batch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:50<00:00, 50.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[../hasil/data_link/sma/batch_31-40.csv] ‚úÖ Disimpan 40 baris\n",
      "‚úÖ Semua batch selesai.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîÑ Mulai scraping {total_halaman} halaman ({total_batch} batch, batch size {batch_size})\")\n",
    "\n",
    "# looping batch secara berurutan (synchronous)\n",
    "for i in tqdm(range(total_batch), desc=\"Scraping batch\"):\n",
    "    start = page_mulai + i * batch_size\n",
    "    end = min(start + batch_size - 1, page_selesai)\n",
    "    nama_file = f\"{folder}/batch_{start}-{end}.csv\"\n",
    "\n",
    "    scrape_pages(start, end, jenjang, nama_file)\n",
    "\n",
    "print(\"‚úÖ Semua batch selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3a775",
   "metadata": {},
   "source": [
    "## **Dengan Multi-Worker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîÑ Mulai scraping {total_halaman} halaman ({total_batch} batch, batch size {batch_size})\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKER) as executor:\n",
    "    futures = []\n",
    "    for i in range(total_batch):\n",
    "        start = page_mulai + i * batch_size\n",
    "        end = min(start + batch_size - 1, page_selesai)\n",
    "        nama_file = f\"{folder}/batch_{start}-{end}.csv\"\n",
    "\n",
    "        futures.append(executor.submit(scrape_pages, start, end, jenjang, nama_file))\n",
    "\n",
    "    # tampilkan progress dengan tqdm\n",
    "    for _ in tqdm(as_completed(futures), total=total_batch, desc=\"Scraping batch\"):\n",
    "        pass\n",
    "\n",
    "print(\"‚úÖ Semua batch selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349efe0",
   "metadata": {},
   "source": [
    "Mengecek Hasil Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d7b839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kode</th>\n",
       "      <th>nama</th>\n",
       "      <th>link_profil</th>\n",
       "      <th>alamat</th>\n",
       "      <th>kabupaten</th>\n",
       "      <th>kota</th>\n",
       "      <th>provinsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20325309</td>\n",
       "      <td>SMA NU HASYIM ASY ARI</td>\n",
       "      <td>https://sekolah.data.kemdikbud.go.id/index.php...</td>\n",
       "      <td>JL. RAYA KARANGJATI RT.03/01, TARUB Karangjati...</td>\n",
       "      <td>Kab. Tegal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69913893</td>\n",
       "      <td>SMA NEGERI 1 WULANDONI</td>\n",
       "      <td>https://sekolah.data.kemdikbud.go.id/index.php...</td>\n",
       "      <td>Jl. Trans Wulandoni Wulandoni Kec. Wulandoni K...</td>\n",
       "      <td>Kab. Lembata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nusa Tenggara Timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20511951</td>\n",
       "      <td>SMA NEGERI 1 PLOSOKLATEN KABUPATEN KEDIRI</td>\n",
       "      <td>https://sekolah.data.kemdikbud.go.id/index.php...</td>\n",
       "      <td>DS.KAWEDUSAN PLOSOKLATEN Kawedusan Kec. Plosok...</td>\n",
       "      <td>Kab. Kediri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20532399</td>\n",
       "      <td>SMAS GALUH HANDAYANI</td>\n",
       "      <td>https://sekolah.data.kemdikbud.go.id/index.php...</td>\n",
       "      <td>Manyar Sambongan 85A Kertajaya Kec. Gubeng Kot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kota Surabaya</td>\n",
       "      <td>Jawa Timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20321976</td>\n",
       "      <td>SMAS THERESIANA WELERI</td>\n",
       "      <td>https://sekolah.data.kemdikbud.go.id/index.php...</td>\n",
       "      <td>JL. TAMTAMA WELERI Penyangkringan Kec. Weleri ...</td>\n",
       "      <td>Kab. Kendal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       kode                                       nama  \\\n",
       "0  20325309                      SMA NU HASYIM ASY ARI   \n",
       "1  69913893                     SMA NEGERI 1 WULANDONI   \n",
       "2  20511951  SMA NEGERI 1 PLOSOKLATEN KABUPATEN KEDIRI   \n",
       "3  20532399                       SMAS GALUH HANDAYANI   \n",
       "4  20321976                     SMAS THERESIANA WELERI   \n",
       "\n",
       "                                         link_profil  \\\n",
       "0  https://sekolah.data.kemdikbud.go.id/index.php...   \n",
       "1  https://sekolah.data.kemdikbud.go.id/index.php...   \n",
       "2  https://sekolah.data.kemdikbud.go.id/index.php...   \n",
       "3  https://sekolah.data.kemdikbud.go.id/index.php...   \n",
       "4  https://sekolah.data.kemdikbud.go.id/index.php...   \n",
       "\n",
       "                                              alamat     kabupaten  \\\n",
       "0  JL. RAYA KARANGJATI RT.03/01, TARUB Karangjati...    Kab. Tegal   \n",
       "1  Jl. Trans Wulandoni Wulandoni Kec. Wulandoni K...  Kab. Lembata   \n",
       "2  DS.KAWEDUSAN PLOSOKLATEN Kawedusan Kec. Plosok...   Kab. Kediri   \n",
       "3  Manyar Sambongan 85A Kertajaya Kec. Gubeng Kot...           NaN   \n",
       "4  JL. TAMTAMA WELERI Penyangkringan Kec. Weleri ...   Kab. Kendal   \n",
       "\n",
       "            kota             provinsi  \n",
       "0            NaN          Jawa Tengah  \n",
       "1            NaN  Nusa Tenggara Timur  \n",
       "2            NaN           Jawa Timur  \n",
       "3  Kota Surabaya           Jawa Timur  \n",
       "4            NaN          Jawa Tengah  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f\"{folder}/batch_1-100.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cebe83",
   "metadata": {},
   "source": [
    "## **Menyatukan batch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fa874",
   "metadata": {},
   "source": [
    "Setelah proses scraping per batch selesai, langkah selanjutnya adalah **menggabungkan semua file CSV** menjadi satu file utama.  \n",
    "Langkah ini memastikan semua data sekolah dari batch berbeda tersimpan dalam satu file `\"semua_sma.csv\"` (tergantung jenjang) yang siap dianalisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ca0b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Ditemukan 38 file untuk digabungkan.\n",
      "1. batch_1-100.csv -> 400 baris\n",
      "2. batch_1001-1100.csv -> 400 baris\n",
      "3. batch_101-200.csv -> 400 baris\n",
      "4. batch_1101-1200.csv -> 400 baris\n",
      "5. batch_1201-1300.csv -> 400 baris\n",
      "6. batch_1301-1400.csv -> 400 baris\n",
      "7. batch_1401-1500.csv -> 400 baris\n",
      "8. batch_1501-1600.csv -> 400 baris\n",
      "9. batch_1601-1700.csv -> 400 baris\n",
      "10. batch_1701-1800.csv -> 400 baris\n",
      "11. batch_1801-1900.csv -> 400 baris\n",
      "12. batch_1901-2000.csv -> 400 baris\n",
      "13. batch_2001-2100.csv -> 400 baris\n",
      "14. batch_201-300.csv -> 400 baris\n",
      "15. batch_2101-2200.csv -> 400 baris\n",
      "16. batch_2201-2300.csv -> 400 baris\n",
      "17. batch_2301-2400.csv -> 400 baris\n",
      "18. batch_2401-2500.csv -> 400 baris\n",
      "19. batch_2501-2600.csv -> 400 baris\n",
      "20. batch_2601-2700.csv -> 400 baris\n",
      "21. batch_2701-2800.csv -> 400 baris\n",
      "22. batch_2801-2900.csv -> 400 baris\n",
      "23. batch_2901-3000.csv -> 400 baris\n",
      "24. batch_3001-3100.csv -> 400 baris\n",
      "25. batch_301-400.csv -> 400 baris\n",
      "26. batch_3101-3200.csv -> 400 baris\n",
      "27. batch_3201-3300.csv -> 400 baris\n",
      "28. batch_3301-3400.csv -> 400 baris\n",
      "29. batch_3401-3500.csv -> 400 baris\n",
      "30. batch_3501-3600.csv -> 400 baris\n",
      "31. batch_3601-3700.csv -> 400 baris\n",
      "32. batch_3701-3800.csv -> 127 baris\n",
      "33. batch_401-500.csv -> 400 baris\n",
      "34. batch_501-600.csv -> 400 baris\n",
      "35. batch_601-700.csv -> 400 baris\n",
      "36. batch_701-800.csv -> 400 baris\n",
      "37. batch_801-900.csv -> 400 baris\n",
      "38. batch_901-1000.csv -> 400 baris\n",
      "\n",
      "‚úÖ Selesai! Total: 14927 baris data digabung dan disimpan di: ../hasil/data_halaman/sma/semua_sma.csv\n"
     ]
    }
   ],
   "source": [
    "# folder hasil batch\n",
    "csv_files = sorted(glob.glob(os.path.join(folder, \"batch_*.csv\")))\n",
    "\n",
    "# cek kalau tidak ada file\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"Tidak ada file batch_*.csv di folder {folder}\")\n",
    "\n",
    "print(f\"üìÇ Ditemukan {len(csv_files)} file untuk digabungkan.\")\n",
    "\n",
    "# baca & gabungkan semua file CSV\n",
    "data_frames = []\n",
    "for idx, file in enumerate(csv_files, start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"{idx}. {os.path.basename(file)} -> {df.shape[0]} baris\")\n",
    "    data_frames.append(df)\n",
    "\n",
    "# concat semua DataFrame jadi satu\n",
    "data_all = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# simpan hasil gabungan\n",
    "output_file = f\"{folder}/semua_{jenjang.lower()}.csv\"\n",
    "data_all.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n‚úÖ Selesai! Total: {len(data_all)} baris data digabung dan disimpan di: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96820221",
   "metadata": {},
   "source": [
    "‚úÖ Hasil Akhir Scraping\n",
    "\n",
    "Proses **Scraping Halaman** akan menghasilkan **file CSV** yang berisi data detail **SMA di seluruh Indonesia** sebanyak **`14.927 sekolah`**.  \n",
    "\n",
    "Kolom pada CSV:\n",
    "\n",
    "| kode | nama | link_profil | alamat | kabupaten | kota | provinsi |\n",
    "|------|------|-------------|--------|-----------|------|----------|\n",
    "\n",
    "File CSV disimpan di folder output sesuai jenjang, misalnya: <br>\n",
    "`../hasil/data_halaman/sma/semua_sma.csv`\n",
    "\n",
    "File CSV ini siap digunakan untuk **scraping data sekolah lebih detail**, yang dilakukan pada notebook: <br>\n",
    "`2_scraping_profil.ipynb`\n",
    "\n",
    "\n",
    "> Dengan file ini, seluruh proses scraping profil sekolah bisa dilakukan secara otomatis dan sistematis, sehingga data siap dipakai untuk analisis lebih lanjut."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
